#!/usr/bin/env python
# coding: utf-8

# # Measurement - synthetic control method (SCM) 

# ## What is SCM
# 
# SCM is a quasi-experimental design to do causal inference, similar to diff-in-diff (DID). 
# 
# In the situation where the random selection is not feasible, or there might be spillovers between treatments and control, quasi-experiments are used to measure the impact of the treatments. 
# 
# The challenge with DID method is that it requires similar covariates between the treated and control groups, which is not always feasible. 
# Another problem is that if the frowth trend from the treatment is different from the trend of the control, DID will be biased, a common problem with non-random data. 
# 
# 
# To work around with this, we use what is known as synthetic control method to measure the treatment outcome against a look-alike generated control population. 
# SCM generates control set by providing formal criteria and explains the relative importance of each donor by employing linear models. 
# What is more, the choice of synthetic control does not rely on post-intervention outcomes, making it impossible to cherry-pick the study design that may affect the conclusions. 
# 
# 
# ### When to use SCM
# SCM is best method when the experiment takes place at aggregate level, eg. country, state, county, and there are only a handful of control and test cases. Due to these charateristics, SCM is the go-to method for large-scale program evaluation. 
# 
# 
# ### Strengths of SCM
# - First and foremost, SCM generated counterfactual is almost the same the treated case. 
# - Secondly, SCM is easy to explain since it mostly employing linear models. You can explain the weights of each covariates by using the weights of the model. 
# 
# 
# ### Challenges with SCM
# - By design, SCM works at aggregate level, not individual level. 
# - Also, it requires a relatively long pre-treatment period so that it could model good counterfactual data. 

# In[1]:


import warnings
warnings.simplefilter("ignore")

import pandas as pd
pd.set_option('display.max_columns', 8)

from sklearn.linear_model import Lasso, ElasticNet, Ridge
import scipy.stats as st


# ## California proposition 99
# 
# To see it in action, let's consider the problem of estimating the effect of cigarette taxation on its consumption. 
# 
# In 1988, California passed a famous Tobacco Tax and Health Protection Act, which became known as Proposition 99. 
# 
# “Its primary effect is to impose a 25-cent per pack state excise tax on the sale of tobacco cigarettes within California, with approximately equivalent excise taxes similarly imposed on the retail sale of other commercial tobacco products, such as cigars and chewing tobacco. Additional restrictions placed on the sale of tobacco include a ban on cigarette vending machines in public areas accessible by juveniles and a ban on the individual sale of single cigarettes. Revenue generated by the act was earmarked for various environmental and health care programs, and anti-tobacco advertisements.”
# 
# To evaluate its effect, we can gather data on cigarette sales from multiple states and across a number of years. In our case, we got data from the years 1970 to 2000 from 39 states. Other states had similar Tobacco control programs and were dropped from the analysis. Here is what our data looks like.

# In[2]:


# # Download data from online source, and store locally
# df = pd.read_csv('https://raw.githubusercontent.com/synth-inference/synthdid/master/data/california_prop99.csv',
#                 sep = ';')
# df.to_csv('data/california_prop99.csv')

df= pd.read_csv('data/california_prop99.csv')


# In[3]:


df.head()


# In[4]:


from matplotlib import pyplot as plt
import numpy as np

# style plots
def write_local_style():
    mpltxt = """patch.linewidth: 0.5\npatch.facecolor: 348ABD  \npatch.edgecolor: EEEEEE\n
    patch.antialiased: True\nlines.solid_capstyle: round\nfont.size: 10.0\n
    font.family: Trebuchet MS\ntext.color: 575757\naxes.facecolor: none\n
    axes.edgecolor: 575757\naxes.spines.left   : True   \naxes.spines.bottom : True\n
    axes.spines.top    : False\naxes.spines.right  : False\naxes.linewidth: 1\naxes.grid: True\n
    axes.titlesize: x-large\naxes.labelsize: large\naxes.labelcolor: 575757\naxes.axisbelow: True       \n
    axes.prop_cycle: cycler('color', ['29ba74', '6e6f73', '295e7e', '670f31', '98b21c', '9a9a9a', '3ead92'])\n
    xtick.color: 575757\nxtick.direction: out\nxtick.labelsize : medium\nxtick.major.width: 1\n
    xtick.major.size: 4      \nytick.color: 575757\nytick.direction: out\nytick.labelsize : medium\n
    ytick.major.width: 1\nytick.major.size: 4\ngrid.color: none\nfigure.facecolor: none\n
    figure.edgecolor: 0.50\nfigure.dpi: 150      \n"""
    with open('data/style/mystyle.mplstyle','w+') as f:
        f.write(mpltxt)

write_local_style()
plt.style.use('data/style/mystyle.mplstyle')


# Here the plot shows the difference between California pre and post vs other states average pre and post.
# 
# A few observations from the plot:
# - Apparently people in California bought fewer cigarettes than national average. 
# - There is a downwards trending in both California and other states of the country
# - It seems like the decreasing trend in California were accelerated after the proposition 99, but we can't say it for sure. 

# In[5]:


ax = plt.subplot(1, 1, 1)

df.assign(california = np.where(df['State'] =='California', 'Calfornia', "National average")).groupby(['Year','california'])['PacksPerCapita'].mean().reset_index().pivot('Year', 'california', 'PacksPerCapita').plot(ax = ax, figsize = (10, 5), lw = 3)

plt.vlines(x=1988, ymin= 40, ymax = 140,
          linestyle=":", lw = 2,
          label = 'Proposition 99')
plt.ylabel("Cigarette Sales Trend")
plt.title("Per-capita cigarette sales (in packs)")
plt.legend()
plt.show()


# To answer the question whether Proposition 99 had an effect on cigarette consumption, we will use the pre-intervention period to build a synthetic control, which means we will build a fake state that resembles very closely the trend of California. 

# # Clean data for downstream work
# 
# Ideally we want to see the data with each state as columns, and dates as rows, so that we can use any machine learning model to use other states as variables and we represent the outcome as a weighted average of the units (i.e. a dot product of the each state PacksPerCapita and regression weight).

# In[6]:


inverted = (df   # filter pre-intervention period
            .pivot(index='State', columns = 'Year')['PacksPerCapita']
            .T) # flip the table to have one column per state

inverted.head()


# # Implement SCM
# 
# Here we will try to build a fake unit that resemble the treated unit
# 
# To do this with linear regression, we will find the weights of each state that can be rebuild to the new fake state. 
# 
# For modeling, we run a regulated regression such as Lasso, Ridge or ElasticNet because we don't want the model to overfit. The regression will return as a set of weights that minimize the square difference between the treated unit and the units in the other states. 

# In[7]:


# training data would be before 1989 when the state of California introduced the Act
train_df = inverted.loc[:1988]


# In[8]:


def create_synthetic_control(train_df, inverted, pool, state = 'California'):
    # other states 
    other_states = [x for x in pool if x != state]
    
    y = train_df[state] # state of california
    X = train_df[other_states] # other states

    weights_regression = ElasticNet(fit_intercept=False, positive=True).fit(X, y).coef_
    weights = pd.DataFrame(data = {'State':X.columns, 
                                   'weights':weights_regression.round(3)})
    print(f"State weights : ")
    print(f"{weights[weights['weights']>0].sort_values('weights', ascending=False)}")

    # Forming the synthetic control
    synth_control = inverted[other_states].dot(weights_regression)
    
    cal = inverted[[state]]
    cal['synth'] = synth_control
    cal['gap'] = cal[state] - synth_control
    return cal, weights


# In[9]:


state_pools = train_df.columns
cal, weights = create_synthetic_control(train_df, inverted, state_pools, state = 'California')


# Now we have the synthetic control, we can plot it with the outcome variable of the state of California

# In[10]:


def print_actual_synth(df, state='California'): 
    plt.figure(figsize=(10,6))

    plt.plot(df.index, df[state], label=state, lw=3,)
    plt.plot(df.index, df['synth'], label="Synthetic Control",lw=3, )

    plt.vlines(x=1988, ymin=40, ymax=140, linestyle=":", lw=2, label="Proposition 99")
    plt.ylabel("Cigarette Sales Trend")
    plt.title("Gap in per-capita cigarette sales (in packs)")
    plt.legend();


# In[11]:


print_actual_synth(cal, state='California')


# # Outliers
# 
# Here we premute the treated and control exhaustively. Since we only have one treated unit, this means that for each unit, we pretend it is the treated while the others are the control. 
# 
# in the end, we will have one synthetic control and effect estimates for each state. What this does is it pretends that the treatment actually happened for another state, not California, and see what would have been the estimated .

# In[12]:


def synthetic_control(state, data):
    train_df = data.loc[:1988]
    use_cols = [x for x in data.columns if not x.endswith('_gap') and x != state]
    y = train_df[state].values # treated state
    X = train_df[use_cols].values  # other states

    weights = Lasso(fit_intercept=False).fit(X, y).coef_

    synth = data[use_cols].dot(weights)

    data[state + '_gap'] = data[state] - synth
    return data


# In[13]:


outlier_data = inverted.copy()
for state in outlier_data.columns:
    outlier_data = synthetic_control(state, outlier_data)


# From the plot, 2 things jumped out: 
# 1. the variance after the intervention is higher than the variance before intervention. This is expected since the synthetic control is designed to minimize the difference in the pre-intervention period.
# 2. There are some states we can't fit very well even in the pre-intervention period. This is also to be expected, since these might be outliers. 

# In[14]:


plt.figure(figsize=(10,6))

plt.plot(cal.index, cal['gap'], label="California", lw=5,)
for state in [x for x in outlier_data.columns if x.endswith('_gap')]:
    plt.plot(outlier_data.index, outlier_data[state])

plt.vlines(x=1988, ymin=-100, ymax=100, linestyle=":", lw=2, label="Proposition 99")
plt.ylabel("Gap in per-capita cigarette sales (in packs)")
plt.title("Before removing outliers")
plt.legend();


# Since the states are pooly fit, we would remove those outliers from our analysis. 
# 
# One way to do this is to make a cut with the mean squared error pre intervention. 

# In[15]:


# Here we remove the outliers that are over a certain percentile 

def identify_outliers(data, percentile):
    train_df = outlier_data.loc[:1988]
    gap_cols = [x for x in train_df.columns if x.endswith('_gap')]
    traim_mse = (train_df[gap_cols] ** 2).mean().reset_index()
    traim_mse.columns = ['State', 'mse']
    traim_mse['State'] = df['State'].str.replace(r'_gap', '')
    
    traim_mse.boxplot()
    
    upper_percentile = np.percentile(traim_mse.mse.values, q=percentile)
    print(f'Upper percentile of mse is {upper_percentile}')

    outliers = traim_mse[(traim_mse['mse']> upper_percentile)]
    print('removing outliers:')
    print(outliers)
    return traim_mse[(traim_mse['mse']<= upper_percentile)]['State'].to_list()


# In[16]:


non_outlier_state= identify_outliers(outlier_data, percentile=75)


# In[17]:


plt.figure(figsize=(10,6))

plt.plot(cal.index, cal['gap'], label="California", lw=5,)
for state in non_outlier_state:
    plt.plot(outlier_data.index, outlier_data[state + '_gap'])

plt.vlines(x=1988, ymin=-100, ymax=100, linestyle=":", lw=2, label="Proposition 99")
plt.ylabel("Gap in per-capita cigarette sales (in packs)")
plt.title("After removing outliers")
plt.legend();


# In[ ]:





# # Recalculate california synthetic control after removing noise

# In[18]:


# Use the non outlier states as new pool
cal_non_outlier, weights = create_synthetic_control(train_df, inverted, non_outlier_state, state = 'California')


# In[19]:


# New plot without outliers as control
print_actual_synth(cal_non_outlier, state='California')


# # Confidence Intervals

# In[20]:


test_df = cal_non_outlier.loc[1990:]
test_df['lift'] = test_df['gap']/test_df['synth']
data = test_df['lift']


# In[21]:


# Sample mean
x_bar = data.mean()
x_bar


# Confidence Intervals Using the t Distribution
# 
# If we’re working with a small sample (n <30), we can use the t.interval() function from the scipy.stats library to calculate a confidence interval for a population mean.

# In[22]:


def mean_confidence_interval(data, confidence=0.95):
    a = 1.0 * np.array(data)
    n = len(a)
    m, se = np.mean(a), st.sem(a) # Mean and standard error
    h = se * st.t.ppf((1 + confidence) / 2., n-1) # t distribution margin of error
    return m, m-h, m+h


# In[23]:


mean_confidence_interval(data)


# In[24]:


# Or simply use one line of code here
st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) 


# In[25]:


# Another way to calculate CI using t distribution
import statsmodels.stats.api as sms

sms.DescrStatsW(data).tconfint_mean()


# Confidence Intervals Using the Normal Distribution
# 
# If we’re working with larger samples (n≥30), we can assume that the sampling distribution of the sample mean is normally distributed (thanks to the Central Limit Theorem) and can instead use the norm.interval() function from the scipy.stats library.

# In[26]:


#create 95% confidence interval for population mean weight
st.norm.interval(alpha=0.95, loc=np.mean(data), scale=st.sem(data))


# # Placebo state
# 
# SCM does not offer standard errors, which makes it harder to get the significance of performance outcome. One way to evaluate this is to perform a placebo test. 
# 
# Placebo tests are more commonly used in medical experiments. During a drug experiment, patients who are administrated drugs tend to show a positive recovery as they believe that the new drug will recover them. This psychological effect also impact the outcome of the experiment. To avoid this, placebos were introduced. Hence the actual impact of the drug will be measured as the difference between the treatment with and without placebo. 
# 
# This practice can be used measure the effectiveness of the SCM as well. The treatment state is replaced with one or many of the control state and synthetic control is generated for this control state. This will prove that there is no identifiable effect on the control from the treatment.  

# In[27]:


# Find the state that has the highest corr with California pre 1989 
train_df.corr()['California'].sort_values(ascending=False).head()


# In[28]:


# Montana has similar scale of sales compare to California

plt.figure(figsize=(10,6))

plt.plot(inverted.index, inverted['California'], label="California", lw=3,)
plt.plot(inverted.index, inverted['Montana'], label="Montana",lw=3,)

plt.vlines(x=1988, ymin=40, ymax=140, linestyle=":", lw=2, label="Proposition 99")
plt.ylabel("Cigarette Sales Trend")
plt.title("Gap in per-capita cigarette sales (in packs)")
plt.legend();


# In[29]:


non_outlier_state_MO = [x for x in non_outlier_state if x != 'Montana']

# Use the non outlier states as new pool
mon_non_outlier, mon_weights = create_synthetic_control(train_df, inverted, 
                                                        non_outlier_state_MO, state = 'Montana')


# In[30]:


# New plot without outliers as control
print_actual_synth(mon_non_outlier, state='Montana')


# In[31]:


mon_non_outlier.tail()


# In[32]:


test_df = mon_non_outlier.loc[1990:]
test_df['lift'] = test_df['gap']/test_df['synth']
data = test_df['lift']
mean_confidence_interval(data)


# Treated California sales go down by 25.0% (mean lift) with CI [-30.7%,-19.4%]. In comparison, Montana untreated, placebo sales go up around 7.3%, with CI [3.6%, 10.9%]. Therefore, SCM measure signifies that the treatment was meaningful.

# In[ ]:





# In[ ]:




